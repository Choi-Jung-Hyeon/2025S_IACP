{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAol1zyDhyer"
      },
      "outputs": [],
      "source": [
        "# DenseNet-121 Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.client import device_lib\n",
        "import kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "OetJ3Vbtx_On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Language: Python\n",
        "# Framework: TensorFlow\n",
        "# Dataset: Kaggle Dog & Cat\n",
        "# (train : Dog 5000, Cat 5000 / validation : Dog 2000, Cat 2000)\n",
        "# (https://www.kaggle.com/datasets/tongpython/cat-and-dog?select=training_set)\n",
        "\n",
        "# Image Size: 224 * 224 * 3\n",
        "# Branch Size: 32\n",
        "# Epoch: 50\n",
        "# Learning Rate: 0.001\n",
        "\n",
        "def DenseNet(x):\n",
        "    # Growth Rate\n",
        "    k = 32\n",
        "    # Compression Factor\n",
        "    compression = 0.5\n",
        "\n",
        "    # 1. Convolution Layer\n",
        "    # Kernel Size: 7 * 7 (stride = 2)\n",
        "    # Output Size: 112 * 112\n",
        "    x = layers.Conv2D(k * 2, (7, 7), strides=2, padding='same', input_shape=(224, 224, 3))(x) # 112 * 112 * 64\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    # 2. Pooling Layer\n",
        "    # Kernel Size: 3 * 3 (stride = 2) -> max pooling\n",
        "    # Output Size: 56 * 56\n",
        "    x = layers.MaxPool2D((3, 3), 2, padding='same')(x) # 56 * 56 * 64\n",
        "\n",
        "    # 3. Dense Block Layer(1)\n",
        "    # 1*1 Conv, 3*3 Conv를 각각 6, 12, 24, 16회 반복\n",
        "    # 이전 모든 feature map들에 대해 접근 및 ResNet과는 달리 이를 concat하여 구현\n",
        "    for i in range(6) :\n",
        "        x_l = layers.Conv2D(k * 4, (1, 1), strides=1, padding='same')(x)    # 56 * 56 * 128\n",
        "        x_l = layers.BatchNormalization()(x_l)\n",
        "        x_l = layers.Activation('relu')(x_l)\n",
        "\n",
        "        x_l = layers.Conv2D(k, (3, 3), strides=1, padding='same')(x_l)  # 56 * 56 * 32\n",
        "        x_l = layers.BatchNormalization()(x_l)\n",
        "        x_l = layers.Activation('relu')(x_l)\n",
        "\n",
        "        x = layers.Concatenate()([x, x_l])  # 96 -> 128 -> 160 -> 192 -> 224 -> 256\n",
        "\n",
        "    # 4. Transition Layer(1)\n",
        "    current_shape = int(x.shape[-1]) # 56 * 56 * 256\n",
        "    x = layers.Conv2D(int(current_shape * compression), (1, 1), strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.AveragePooling2D((2, 2), strides=2, padding='same')(x)   # 28 * 28\n",
        "\n",
        "    # 5. Dense Block Layer(2)\n",
        "    for i in range(6) :\n",
        "        x_l = layers.Conv2D(k * 4, (1, 1), strides=1, padding='same')(x)\n",
        "        x_l = layers.BatchNormalization()(x_l)\n",
        "        x_l = layers.Activation('relu')(x_l)\n",
        "\n",
        "        x_l = layers.Conv2D(k, (3, 3), strides=1, padding='same')(x_l)\n",
        "        x_l = layers.BatchNormalization()(x_l)\n",
        "        x_l = layers.Activation('relu')(x_l)\n",
        "\n",
        "        x = layers.Concatenate()([x, x_l])\n",
        "\n",
        "    # 6. Transition Layer(2)\n",
        "    current_shape = int(x.shape[-1])\n",
        "    x = layers.Conv2D(int(current_shape * compression), (1, 1), strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.AveragePooling2D((2, 2), strides=2, padding='same')(x)   # 14 * 14\n",
        "\n",
        "    # 7. Dense Block Layer(3)\n",
        "    for i in range(6) :\n",
        "        x_l = layers.Conv2D(k * 4, (1, 1), strides=1, padding='same')(x)\n",
        "        x_l = layers.BatchNormalization()(x_l)\n",
        "        x_l = layers.Activation('relu')(x_l)\n",
        "\n",
        "        x_l = layers.Conv2D(k, (3, 3), strides=1, padding='same')(x_l)\n",
        "        x_l = layers.BatchNormalization()(x_l)\n",
        "        x_l = layers.Activation('relu')(x_l)\n",
        "\n",
        "        x = layers.Concatenate()([x, x_l])\n",
        "\n",
        "    # 8. Transition Layer(3)\n",
        "    current_shape = int(x.shape[-1])\n",
        "    x = layers.Conv2D(int(current_shape * compression), (1, 1), strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.AveragePooling2D((2, 2), strides=2, padding='same')(x)   # 7 * 7\n",
        "\n",
        "    # 9. Dense Block Layer(4)\n",
        "    for i in range(6) :\n",
        "        x_l = layers.Conv2D(k * 4, (1, 1), strides=1, padding='same')(x)\n",
        "        x_l = layers.BatchNormalization()(x_l)\n",
        "        x_l = layers.Activation('relu')(x_l)\n",
        "\n",
        "        x_l = layers.Conv2D(k, (3, 3), strides=1, padding='same')(x_l)\n",
        "        x_l = layers.BatchNormalization()(x_l)\n",
        "        x_l = layers.Activation('relu')(x_l)\n",
        "\n",
        "        x = layers.Concatenate()([x, x_l])\n",
        "\n",
        "    # 10. Classification Layer\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    # classes = 2 (softmax)\n",
        "    x = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "BnhFxv91x2Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter\n",
        "batch_size = 32\n",
        "epoch = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Dataset (Kaggle Cat and Dog Dataset)\n",
        "#dataset_path = kagglehub.dataset_download(\"tongpython/cat-and-dog\")\n",
        "dataset_path = os.path.join('/home/fourmi103/archieve')\n",
        "train_dataset_path = dataset_path + '/train_set'\n",
        "print(\"Path to train dataset files: \", train_dataset_path)\n",
        "train_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
        "train_dataset = train_data_generator.flow_from_directory(train_dataset_path,\n",
        "                                                         shuffle=True,\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         class_mode='categorical')\n",
        "\n",
        "valid_dataset_path = dataset_path + '/validation_set'\n",
        "valid_data_generator = ImageDataGenerator(rescale=1. / 255)\n",
        "valid_dataset = valid_data_generator.flow_from_directory(valid_dataset_path,\n",
        "                                                         shuffle=True,\n",
        "                                                         target_size=(224, 224),\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         class_mode='categorical')\n",
        "\n",
        "\n",
        "# Train\n",
        "input_shape = layers.Input(shape=(224, 224, 3), dtype='float32', name='input')\n",
        "model = tf.keras.Model(input_shape, DenseNet(input_shape))\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['acc'])\n",
        "model.summary()\n",
        "train = model.fit_generator(train_dataset, epochs=epoch, validation_data=valid_dataset)\n",
        "\n",
        "# Accuracy graph\n",
        "plt.figure(1)\n",
        "plt.plot(train.history['acc'])\n",
        "plt.plot(train.history['val_acc'])\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig('DenseNet_Accuracy_1.png')\n",
        "\n",
        "# Loss graph\n",
        "plt.figure(2)\n",
        "plt.plot(train.history['loss'])\n",
        "plt.plot(train.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig('DenseNet_Loss_1.png')"
      ],
      "metadata": {
        "id": "GOsDndTcyPFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}