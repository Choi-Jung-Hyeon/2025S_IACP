{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLLzNx1ylMs3"
      },
      "outputs": [],
      "source": [
        "!pip install -q timm diffusers lpips transformers accelerate\n",
        "!pip install -q torch torchvision pillow numpy scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.hub import load_state_dict_from_url\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional, Tuple, List, Dict, Union\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "QbTPp04BlpFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from diffusers import AutoencoderKL\n",
        "import lpips\n",
        "from google.colab import files\n",
        "import io\n",
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "aWNJ9xjcls6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "LUYwWjxWlxrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DINO v2\n",
        "def load_dinov2_extractor(model_name: str = 'vit_large_patch14_dinov2.lvd142m') -> nn.Module:\n",
        "    print(f\"Loading DINOv2 model: {model_name}\")\n",
        "\n",
        "    model = timm.create_model(\n",
        "        model_name,\n",
        "        pretrained=False,\n",
        "        num_classes=0,\n",
        "        global_pool='avg'\n",
        "    )\n",
        "\n",
        "    # 가중치 안가져오고 학습시킬 수는 없을까? 왜 자꾸 오류나지\n",
        "    url = f\"https://huggingface.co/timm/{model_name}/resolve/main/pytorch_model.bin\"\n",
        "    state_dict = load_state_dict_from_url(url, map_location='cpu')\n",
        "\n",
        "    if 'norm.weight' in state_dict and 'fc_norm.weight' not in state_dict:\n",
        "        state_dict['fc_norm.weight'] = state_dict.pop('norm.weight')\n",
        "        state_dict['fc_norm.bias'] = state_dict.pop('norm.bias')\n",
        "        print(\"State_dict keys 'norm' were successfully renamed to 'fc_norm'\")\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print(\"✓ DINOv2 extractor loaded successfully\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "oPMLc5O-l4tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AutoEncoder\n",
        "def load_sd_vae(model_id: str = \"stabilityai/stable-diffusion-2-1\") -> AutoencoderKL:\n",
        "    print(f\"Loading Stable Diffusion VAE from: {model_id}...\")\n",
        "\n",
        "    vae = AutoencoderKL.from_pretrained(\n",
        "        model_id,\n",
        "        subfolder=\"vae\",\n",
        "        torch_dtype=torch.float16 if device.type == 'cuda' else torch.float32\n",
        "    )\n",
        "\n",
        "    vae.eval()\n",
        "    vae = vae.to(device)\n",
        "\n",
        "    for param in vae.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print(\"✓ VAE loaded successfully\")\n",
        "    return vae"
      ],
      "metadata": {
        "id": "S7lV4-y2mc75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RIGID\n",
        "# S(x) = 1{sim(f(x), f(x + λ·δ)) ≤ ε}; δ ~ N(0,I)\n",
        "def detect_with_rigid(\n",
        "    image_tensor: torch.Tensor,             # B, C, H, W 형태의 정규화된 입력 이미지 텐서\n",
        "    dinov2_feature_extractor: nn.Module,    # 특징 추출기\n",
        "    noise_level: float = 0.05               # 이미지에 추가할 가우시안 노이즈의 표준편차 (λ)\n",
        ") -> torch.Tensor:\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 원본 이미지에서 특징 추출\n",
        "        original_features = dinov2_feature_extractor(image_tensor)\n",
        "\n",
        "        # 가우시안 노이즈 생성 (δ ~ N(0,I))\n",
        "        noise = torch.randn_like(image_tensor) * noise_level\n",
        "\n",
        "        # 노이즈가 추가된 이미지 생성\n",
        "        noisy_image = image_tensor + noise\n",
        "\n",
        "        # 노이즈 이미지에서 특징 추출\n",
        "        noisy_features = dinov2_feature_extractor(noisy_image)\n",
        "\n",
        "        # 코사인 유사도 계산\n",
        "        # F.cosine_similarity는 배치 차원을 유지하면서 계산\n",
        "        cosine_similarity = F.cosine_similarity(\n",
        "            original_features,\n",
        "            noisy_features,\n",
        "            dim=1\n",
        "        )\n",
        "\n",
        "        # 배치 크기가 1보다 큰 경우 차원 조정\n",
        "        if cosine_similarity.dim() == 0:\n",
        "            cosine_similarity = cosine_similarity.unsqueeze(0)\n",
        "\n",
        "    return cosine_similarity\n",
        "\n",
        "# 원본과 노이즈 이미지 특징 간의 코사인 유사도 점수\n",
        "# 낮은 값일수록 AI 생성 이미지일 가능성이 높음"
      ],
      "metadata": {
        "id": "i5AH5r6Wmt9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AEROBLADE\n",
        "# ∆AE(x) = d(x, D(E(x))) where d is LPIPS distance\n",
        "def detect_with_aeroblade(\n",
        "    image_tensor: torch.Tensor,             # B, C, H, W 형태의 입력 이미지 텐서 [-1, 1]\n",
        "    diffusion_autoencoder: AutoencoderKL,   # Stable Diffusion의 사전 학습된 VAE\n",
        "    lpips_loss_fn: lpips.LPIPS              # LPIPS 손실 함수\n",
        ") -> torch.Tensor:\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # VAE 인코더를 통해 latent 표현 획득\n",
        "        if device.type == 'cuda' and diffusion_autoencoder.dtype == torch.float16:\n",
        "            with autocast():\n",
        "                latent_dist = diffusion_autoencoder.encode(image_tensor)\n",
        "                latent = latent_dist.latent_dist.sample()\n",
        "\n",
        "                # VAE 디코더를 통해 이미지 복원\n",
        "                reconstructed = diffusion_autoencoder.decode(latent).sample\n",
        "        else:\n",
        "            latent_dist = diffusion_autoencoder.encode(image_tensor)\n",
        "            latent = latent_dist.latent_dist.sample()\n",
        "            reconstructed = diffusion_autoencoder.decode(latent).sample\n",
        "\n",
        "        # LPIPS 복원 오류 계산 [-1, 1]\n",
        "        lpips_distance = lpips_loss_fn(image_tensor, reconstructed)\n",
        "\n",
        "        # 배치 차원에서 평균 계산 (spatial dimensions에 대해)\n",
        "        lpips_score = lpips_distance.squeeze()\n",
        "\n",
        "        # 스칼라로 변환 (배치 크기가 1인 경우)\n",
        "        if lpips_score.dim() == 0:\n",
        "            lpips_score = lpips_score.unsqueeze(0)\n",
        "\n",
        "    return lpips_score\n",
        "\n",
        "# 원본과 복원 이미지 간의 LPIPS 복원 오류 점수\n",
        "# 낮은 값일수록 AI 생성 이미지일 가능성이 높음"
      ],
      "metadata": {
        "id": "eQd9dQgGnkdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"<모델 초기화>\")\n",
        "dinov2_model = load_dinov2_extractor()\n",
        "sd_vae = load_sd_vae()\n",
        "lpips_fn = lpips.LPIPS(net='vgg').to(device)\n",
        "lpips_fn.eval()\n",
        "print(\"<모델 로드 완료>\")"
      ],
      "metadata": {
        "id": "jwlnev8loPKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 전처리\n",
        "class ImagePreprocessor:\n",
        "    def __init__(self, target_size: int = 518): # DINOv2 입력을 위한 목표 이미지 크기\n",
        "        self.target_size = target_size\n",
        "\n",
        "        # DINOv2용 변환 (ImageNet 정규화)\n",
        "        self.dinov2_transform = transforms.Compose([\n",
        "            transforms.Resize((target_size, target_size), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # VAE용 변환 ([-1, 1] 정규화)\n",
        "        self.vae_transform = transforms.Compose([\n",
        "            transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "    def process_for_dinov2(self, image: Image.Image) -> torch.Tensor:\n",
        "        return self.dinov2_transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    def process_for_vae(self, image: Image.Image) -> torch.Tensor:\n",
        "        return self.vae_transform(image).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "YfBGQKMqzGYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ImagePreprocessor()"
      ],
      "metadata": {
        "id": "kJRIptnFzZG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(results: List[Dict]):\n",
        "    num_images = len(results)\n",
        "    fig, axes = plt.subplots(num_images, 3, figsize=(15, 5 * num_images), squeeze=False)\n",
        "\n",
        "    for idx, result in enumerate(results):\n",
        "        axes[idx, 0].imshow(result['image'])\n",
        "        axes[idx, 0].set_title(f\"Input: {result['name']}\", fontsize=12, fontweight='bold')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        rigid_score = result['rigid_score']\n",
        "        rigid_color = 'green' if rigid_score > 0.998 else 'red'\n",
        "        axes[idx, 1].barh(['RIGID'], [rigid_score], color=rigid_color, alpha=0.7)\n",
        "        axes[idx, 1].set_xlim(0, 1)\n",
        "        axes[idx, 1].set_xlabel('Cosine Similarity (Higher is Real)')\n",
        "        axes[idx, 1].set_title(f\"RIGID Score: {rigid_score:.4f}\")\n",
        "        axes[idx, 1].axvline(x=0.998, color='black', linestyle='--', alpha=0.5)\n",
        "\n",
        "        aeroblade_score = result['aeroblade_score']\n",
        "        aero_color = 'green' if aeroblade_score > 0.085 else 'red'\n",
        "        axes[idx, 2].barh(['AEROBLADE'], [aeroblade_score], color=aero_color, alpha=0.7)\n",
        "        axes[idx, 2].set_xlim(0, 0.5)\n",
        "        axes[idx, 2].set_xlabel('LPIPS Distance (Higher is Real)')\n",
        "        axes[idx, 2].set_title(f\"AEROBLADE Score: {aeroblade_score:.4f}\")\n",
        "        axes[idx, 2].axvline(x=0.085, color='black', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.suptitle('AI-Generated Image Detection Results', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aGo0i7Fa40QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_detection_demo():\n",
        "    print(\"🔍 AI 생성 이미지 탐지 데모\")\n",
        "    print(\"\\n📁 이미지를 업로드해주세요.\")\n",
        "    print(\"  1. 실제 이미지 1개\")\n",
        "    print(\"  2. AI 생성 이미지 1개\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if len(uploaded) != 2:\n",
        "        print(f\"❌ 오류: 2개의 이미지를 업로드해야 합니다.\")\n",
        "        return\n",
        "\n",
        "    images, image_names = [], []\n",
        "    for filename, content in uploaded.items():\n",
        "        try:\n",
        "            image = Image.open(io.BytesIO(content)).convert('RGB')\n",
        "            images.append(image)\n",
        "            image_names.append(filename)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류: {filename} 파일을 열 수 없습니다. {str(e)}\")\n",
        "            return\n",
        "\n",
        "    print(f\"\\n✓ 이미지 로드 완료: {image_names}\")\n",
        "\n",
        "    results = []\n",
        "    for image, name in zip(images, image_names):\n",
        "        print(f\"\\n\\n분석 중: {name}\\n\")\n",
        "\n",
        "        dinov2_input = preprocessor.process_for_dinov2(image)\n",
        "        vae_input = preprocessor.process_for_vae(image)\n",
        "\n",
        "        rigid_score = detect_with_rigid(dinov2_input, dinov2_model).item()\n",
        "        aeroblade_score = detect_with_aeroblade(vae_input, sd_vae, lpips_fn).item()\n",
        "\n",
        "        results.append({\n",
        "            'name': name, 'image': image,\n",
        "            'rigid_score': rigid_score, 'aeroblade_score': aeroblade_score\n",
        "        })\n",
        "\n",
        "        print(f\"📊 RIGID Score: {rigid_score:.4f}\")\n",
        "        print(f\"   → {'🟢 실제 이미지' if rigid_score > 0.998 else '🔴 AI 생성 의심'}\")\n",
        "        print(f\"\\n📊 AEROBLADE Score: {aeroblade_score:.4f}\")\n",
        "        print(f\"   → {'🟢 실제 이미지' if aeroblade_score > 0.085 else '🔴 AI 생성 의심'}\")\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "    visualize_results(results)\n",
        "    return results"
      ],
      "metadata": {
        "id": "DHtc-R7ozb2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **사용방법**\n",
        "- 아래 코드 셀을 실행한 후 나타나는 **'파일 선택'** 버튼을 클릭하세요\n",
        "- **정확히 2개의 이미지**를 업로드해야 합니다.\n",
        "  1. 첫 번째 이미지: **실제(Real) 이미지**\n",
        "  2. 두 번째 이미지: **AI 생성(Fake) 이미지**\n",
        "- 지원 형식: JPG, PNG, WEBP\n",
        "- 권장 이미지 크기: 512x512 픽셀 이상"
      ],
      "metadata": {
        "id": "SpIWvqh2zlxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_detection_demo()"
      ],
      "metadata": {
        "id": "ttk5bizk48Ks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}