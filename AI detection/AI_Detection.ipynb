{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLLzNx1ylMs3"
      },
      "outputs": [],
      "source": [
        "!pip install -q timm diffusers lpips transformers accelerate\n",
        "!pip install -q torch torchvision pillow numpy scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.hub import load_state_dict_from_url\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional, Tuple, List, Dict, Union\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "QbTPp04BlpFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from diffusers import AutoencoderKL\n",
        "import lpips\n",
        "from google.colab import files\n",
        "import io\n",
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "aWNJ9xjcls6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "LUYwWjxWlxrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DINO v2\n",
        "def load_dinov2_extractor(model_name: str = 'vit_large_patch14_dinov2.lvd142m') -> nn.Module:\n",
        "    print(f\"Loading DINOv2 model: {model_name}\")\n",
        "\n",
        "    model = timm.create_model(\n",
        "        model_name,\n",
        "        pretrained=False,\n",
        "        num_classes=0,\n",
        "        global_pool='avg'\n",
        "    )\n",
        "\n",
        "    # ê°€ì¤‘ì¹˜ ì•ˆê°€ì ¸ì˜¤ê³  í•™ìŠµì‹œí‚¬ ìˆ˜ëŠ” ì—†ì„ê¹Œ? ì™œ ìê¾¸ ì˜¤ë¥˜ë‚˜ì§€\n",
        "    url = f\"https://huggingface.co/timm/{model_name}/resolve/main/pytorch_model.bin\"\n",
        "    state_dict = load_state_dict_from_url(url, map_location='cpu')\n",
        "\n",
        "    if 'norm.weight' in state_dict and 'fc_norm.weight' not in state_dict:\n",
        "        state_dict['fc_norm.weight'] = state_dict.pop('norm.weight')\n",
        "        state_dict['fc_norm.bias'] = state_dict.pop('norm.bias')\n",
        "        print(\"State_dict keys 'norm' were successfully renamed to 'fc_norm'\")\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print(\"âœ“ DINOv2 extractor loaded successfully\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "oPMLc5O-l4tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AutoEncoder\n",
        "def load_sd_vae(model_id: str = \"stabilityai/stable-diffusion-2-1\") -> AutoencoderKL:\n",
        "    print(f\"Loading Stable Diffusion VAE from: {model_id}...\")\n",
        "\n",
        "    vae = AutoencoderKL.from_pretrained(\n",
        "        model_id,\n",
        "        subfolder=\"vae\",\n",
        "        torch_dtype=torch.float16 if device.type == 'cuda' else torch.float32\n",
        "    )\n",
        "\n",
        "    vae.eval()\n",
        "    vae = vae.to(device)\n",
        "\n",
        "    for param in vae.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print(\"âœ“ VAE loaded successfully\")\n",
        "    return vae"
      ],
      "metadata": {
        "id": "S7lV4-y2mc75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RIGID\n",
        "# S(x) = 1{sim(f(x), f(x + Î»Â·Î´)) â‰¤ Îµ}; Î´ ~ N(0,I)\n",
        "def detect_with_rigid(\n",
        "    image_tensor: torch.Tensor,             # B, C, H, W í˜•íƒœì˜ ì •ê·œí™”ëœ ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ\n",
        "    dinov2_feature_extractor: nn.Module,    # íŠ¹ì§• ì¶”ì¶œê¸°\n",
        "    noise_level: float = 0.05               # ì´ë¯¸ì§€ì— ì¶”ê°€í•  ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆì˜ í‘œì¤€í¸ì°¨ (Î»)\n",
        ") -> torch.Tensor:\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ì¶”ì¶œ\n",
        "        original_features = dinov2_feature_extractor(image_tensor)\n",
        "\n",
        "        # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ìƒì„± (Î´ ~ N(0,I))\n",
        "        noise = torch.randn_like(image_tensor) * noise_level\n",
        "\n",
        "        # ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ ì´ë¯¸ì§€ ìƒì„±\n",
        "        noisy_image = image_tensor + noise\n",
        "\n",
        "        # ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ì¶”ì¶œ\n",
        "        noisy_features = dinov2_feature_extractor(noisy_image)\n",
        "\n",
        "        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
        "        # F.cosine_similarityëŠ” ë°°ì¹˜ ì°¨ì›ì„ ìœ ì§€í•˜ë©´ì„œ ê³„ì‚°\n",
        "        cosine_similarity = F.cosine_similarity(\n",
        "            original_features,\n",
        "            noisy_features,\n",
        "            dim=1\n",
        "        )\n",
        "\n",
        "        # ë°°ì¹˜ í¬ê¸°ê°€ 1ë³´ë‹¤ í° ê²½ìš° ì°¨ì› ì¡°ì •\n",
        "        if cosine_similarity.dim() == 0:\n",
        "            cosine_similarity = cosine_similarity.unsqueeze(0)\n",
        "\n",
        "    return cosine_similarity\n",
        "\n",
        "# ì›ë³¸ê³¼ ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ íŠ¹ì§• ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì ìˆ˜\n",
        "# ë‚®ì€ ê°’ì¼ìˆ˜ë¡ AI ìƒì„± ì´ë¯¸ì§€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ"
      ],
      "metadata": {
        "id": "i5AH5r6Wmt9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AEROBLADE\n",
        "# âˆ†AE(x) = d(x, D(E(x))) where d is LPIPS distance\n",
        "def detect_with_aeroblade(\n",
        "    image_tensor: torch.Tensor,             # B, C, H, W í˜•íƒœì˜ ì…ë ¥ ì´ë¯¸ì§€ í…ì„œ [-1, 1]\n",
        "    diffusion_autoencoder: AutoencoderKL,   # Stable Diffusionì˜ ì‚¬ì „ í•™ìŠµëœ VAE\n",
        "    lpips_loss_fn: lpips.LPIPS              # LPIPS ì†ì‹¤ í•¨ìˆ˜\n",
        ") -> torch.Tensor:\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # VAE ì¸ì½”ë”ë¥¼ í†µí•´ latent í‘œí˜„ íšë“\n",
        "        if device.type == 'cuda' and diffusion_autoencoder.dtype == torch.float16:\n",
        "            with autocast():\n",
        "                latent_dist = diffusion_autoencoder.encode(image_tensor)\n",
        "                latent = latent_dist.latent_dist.sample()\n",
        "\n",
        "                # VAE ë””ì½”ë”ë¥¼ í†µí•´ ì´ë¯¸ì§€ ë³µì›\n",
        "                reconstructed = diffusion_autoencoder.decode(latent).sample\n",
        "        else:\n",
        "            latent_dist = diffusion_autoencoder.encode(image_tensor)\n",
        "            latent = latent_dist.latent_dist.sample()\n",
        "            reconstructed = diffusion_autoencoder.decode(latent).sample\n",
        "\n",
        "        # LPIPS ë³µì› ì˜¤ë¥˜ ê³„ì‚° [-1, 1]\n",
        "        lpips_distance = lpips_loss_fn(image_tensor, reconstructed)\n",
        "\n",
        "        # ë°°ì¹˜ ì°¨ì›ì—ì„œ í‰ê·  ê³„ì‚° (spatial dimensionsì— ëŒ€í•´)\n",
        "        lpips_score = lpips_distance.squeeze()\n",
        "\n",
        "        # ìŠ¤ì¹¼ë¼ë¡œ ë³€í™˜ (ë°°ì¹˜ í¬ê¸°ê°€ 1ì¸ ê²½ìš°)\n",
        "        if lpips_score.dim() == 0:\n",
        "            lpips_score = lpips_score.unsqueeze(0)\n",
        "\n",
        "    return lpips_score\n",
        "\n",
        "# ì›ë³¸ê³¼ ë³µì› ì´ë¯¸ì§€ ê°„ì˜ LPIPS ë³µì› ì˜¤ë¥˜ ì ìˆ˜\n",
        "# ë‚®ì€ ê°’ì¼ìˆ˜ë¡ AI ìƒì„± ì´ë¯¸ì§€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ"
      ],
      "metadata": {
        "id": "eQd9dQgGnkdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"<ëª¨ë¸ ì´ˆê¸°í™”>\")\n",
        "dinov2_model = load_dinov2_extractor()\n",
        "sd_vae = load_sd_vae()\n",
        "lpips_fn = lpips.LPIPS(net='vgg').to(device)\n",
        "lpips_fn.eval()\n",
        "print(\"<ëª¨ë¸ ë¡œë“œ ì™„ë£Œ>\")"
      ],
      "metadata": {
        "id": "jwlnev8loPKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
        "class ImagePreprocessor:\n",
        "    def __init__(self, target_size: int = 518): # DINOv2 ì…ë ¥ì„ ìœ„í•œ ëª©í‘œ ì´ë¯¸ì§€ í¬ê¸°\n",
        "        self.target_size = target_size\n",
        "\n",
        "        # DINOv2ìš© ë³€í™˜ (ImageNet ì •ê·œí™”)\n",
        "        self.dinov2_transform = transforms.Compose([\n",
        "            transforms.Resize((target_size, target_size), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # VAEìš© ë³€í™˜ ([-1, 1] ì •ê·œí™”)\n",
        "        self.vae_transform = transforms.Compose([\n",
        "            transforms.Resize((512, 512), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "    def process_for_dinov2(self, image: Image.Image) -> torch.Tensor:\n",
        "        return self.dinov2_transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    def process_for_vae(self, image: Image.Image) -> torch.Tensor:\n",
        "        return self.vae_transform(image).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "YfBGQKMqzGYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ImagePreprocessor()"
      ],
      "metadata": {
        "id": "kJRIptnFzZG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(results: List[Dict]):\n",
        "    num_images = len(results)\n",
        "    fig, axes = plt.subplots(num_images, 3, figsize=(15, 5 * num_images), squeeze=False)\n",
        "\n",
        "    for idx, result in enumerate(results):\n",
        "        axes[idx, 0].imshow(result['image'])\n",
        "        axes[idx, 0].set_title(f\"Input: {result['name']}\", fontsize=12, fontweight='bold')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        rigid_score = result['rigid_score']\n",
        "        rigid_color = 'green' if rigid_score > 0.998 else 'red'\n",
        "        axes[idx, 1].barh(['RIGID'], [rigid_score], color=rigid_color, alpha=0.7)\n",
        "        axes[idx, 1].set_xlim(0, 1)\n",
        "        axes[idx, 1].set_xlabel('Cosine Similarity (Higher is Real)')\n",
        "        axes[idx, 1].set_title(f\"RIGID Score: {rigid_score:.4f}\")\n",
        "        axes[idx, 1].axvline(x=0.998, color='black', linestyle='--', alpha=0.5)\n",
        "\n",
        "        aeroblade_score = result['aeroblade_score']\n",
        "        aero_color = 'green' if aeroblade_score > 0.085 else 'red'\n",
        "        axes[idx, 2].barh(['AEROBLADE'], [aeroblade_score], color=aero_color, alpha=0.7)\n",
        "        axes[idx, 2].set_xlim(0, 0.5)\n",
        "        axes[idx, 2].set_xlabel('LPIPS Distance (Higher is Real)')\n",
        "        axes[idx, 2].set_title(f\"AEROBLADE Score: {aeroblade_score:.4f}\")\n",
        "        axes[idx, 2].axvline(x=0.085, color='black', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.suptitle('AI-Generated Image Detection Results', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aGo0i7Fa40QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_detection_demo():\n",
        "    print(\"ğŸ” AI ìƒì„± ì´ë¯¸ì§€ íƒì§€ ë°ëª¨\")\n",
        "    print(\"\\nğŸ“ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
        "    print(\"  1. ì‹¤ì œ ì´ë¯¸ì§€ 1ê°œ\")\n",
        "    print(\"  2. AI ìƒì„± ì´ë¯¸ì§€ 1ê°œ\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if len(uploaded) != 2:\n",
        "        print(f\"âŒ ì˜¤ë¥˜: 2ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    images, image_names = [], []\n",
        "    for filename, content in uploaded.items():\n",
        "        try:\n",
        "            image = Image.open(io.BytesIO(content)).convert('RGB')\n",
        "            images.append(image)\n",
        "            image_names.append(filename)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜: {filename} íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {str(e)}\")\n",
        "            return\n",
        "\n",
        "    print(f\"\\nâœ“ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {image_names}\")\n",
        "\n",
        "    results = []\n",
        "    for image, name in zip(images, image_names):\n",
        "        print(f\"\\n\\në¶„ì„ ì¤‘: {name}\\n\")\n",
        "\n",
        "        dinov2_input = preprocessor.process_for_dinov2(image)\n",
        "        vae_input = preprocessor.process_for_vae(image)\n",
        "\n",
        "        rigid_score = detect_with_rigid(dinov2_input, dinov2_model).item()\n",
        "        aeroblade_score = detect_with_aeroblade(vae_input, sd_vae, lpips_fn).item()\n",
        "\n",
        "        results.append({\n",
        "            'name': name, 'image': image,\n",
        "            'rigid_score': rigid_score, 'aeroblade_score': aeroblade_score\n",
        "        })\n",
        "\n",
        "        print(f\"ğŸ“Š RIGID Score: {rigid_score:.4f}\")\n",
        "        print(f\"   â†’ {'ğŸŸ¢ ì‹¤ì œ ì´ë¯¸ì§€' if rigid_score > 0.998 else 'ğŸ”´ AI ìƒì„± ì˜ì‹¬'}\")\n",
        "        print(f\"\\nğŸ“Š AEROBLADE Score: {aeroblade_score:.4f}\")\n",
        "        print(f\"   â†’ {'ğŸŸ¢ ì‹¤ì œ ì´ë¯¸ì§€' if aeroblade_score > 0.085 else 'ğŸ”´ AI ìƒì„± ì˜ì‹¬'}\")\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "    visualize_results(results)\n",
        "    return results"
      ],
      "metadata": {
        "id": "DHtc-R7ozb2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **ì‚¬ìš©ë°©ë²•**\n",
        "- ì•„ë˜ ì½”ë“œ ì…€ì„ ì‹¤í–‰í•œ í›„ ë‚˜íƒ€ë‚˜ëŠ” **'íŒŒì¼ ì„ íƒ'** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”\n",
        "- **ì •í™•íˆ 2ê°œì˜ ì´ë¯¸ì§€**ë¥¼ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "  1. ì²« ë²ˆì§¸ ì´ë¯¸ì§€: **ì‹¤ì œ(Real) ì´ë¯¸ì§€**\n",
        "  2. ë‘ ë²ˆì§¸ ì´ë¯¸ì§€: **AI ìƒì„±(Fake) ì´ë¯¸ì§€**\n",
        "- ì§€ì› í˜•ì‹: JPG, PNG, WEBP\n",
        "- ê¶Œì¥ ì´ë¯¸ì§€ í¬ê¸°: 512x512 í”½ì…€ ì´ìƒ"
      ],
      "metadata": {
        "id": "SpIWvqh2zlxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_detection_demo()"
      ],
      "metadata": {
        "id": "ttk5bizk48Ks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}